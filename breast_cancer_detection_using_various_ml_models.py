# -*- coding: utf-8 -*-
"""Breast Cancer Detection using various ML models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K5QYkwZ6n3VVAdXQbM8YcGXo0m7WEnuo
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""Data Exploration"""

data = pd.read_csv('/content/data.csv')
data.head()

data.shape

data.describe()

data.dtypes

"""Missing values"""

data.isna().sum()

data_fe = data.drop(['Unnamed: 32','id'], axis=1)
data_fe

#changing the diagnosis labels to 0 and 1---B=0, M=1
data_fe['diagnosis'] = data_fe['diagnosis'].replace(['B','M'],[0,1])

data_fe

#number of samples(rows) and features(columns)
data_fe.shape

data_fe.describe()

#count of number of Benign(0) and Malignant(1) samples
data_fe['diagnosis'].value_counts()

"""Plot of number of Benign(B) and Malignant(M) samples """

sns.countplot(data_fe['diagnosis'])

data_fe.dtypes

#convert 'diagnosis' object type to int type
data_fe['diagnosis']=data_fe['diagnosis'].astype(str).astype(int)
data_fe.dtypes

#pair-plots of various features
sns.pairplot(data_fe.iloc[:,0:9], hue='diagnosis')

data_corr = data_fe.corr()
data_corr

plt.subplots(figsize=(20,20))
sns.heatmap(data_corr, annot=True, fmt='0.2f')

data_fe

X_data = data_fe.drop(['diagnosis'], axis=1)
Y_data = data_fe['diagnosis']

#split the dataset into training set(70%) and test set(30%)
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.3, random_state = 0)

#Scaling the data
from sklearn.preprocessing import StandardScaler
s_scaling = StandardScaler()
X_train = s_scaling.fit_transform(X_train)
X_test = s_scaling.fit_transform(X_test)

"""Various Machine Learning Classification Algorithms"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
from sklearn.metrics import confusion_matrix, classification_report,accuracy_score,f1_score,roc_curve,roc_auc_score,auc,precision_recall_curve,average_precision_score

# ROC curve
def plot_roc():
    plt.plot(fpr, tpr, label = 'ROC curve', linewidth = 2)
    plt.plot([0,1],[0,1], 'k--', linewidth = 2)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.show();

# Precision-recall curve
def plot_precision_recall():
    plt.step(recall, precision, color = 'b', alpha = 0.2,
             where = 'post')
    plt.fill_between(recall, precision, step ='post', alpha = 0.2,
                 color = 'b')

    plt.plot(recall, precision, linewidth=2)
    plt.xlim([0.0,1])
    plt.ylim([0.0,1.05])
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision Recall Curve')
    plt.show();

"""Logistic Regression"""

def log_reg(X_train, Y_train):
  lg_reg = LogisticRegression()
  lg_reg.fit(X_train, Y_train)

  score = lg_reg.score(X_train, Y_train)
  Y_pred = lg_reg.predict(X_test)

  return score, Y_pred

train_acc, Y_pred = log_reg(X_train, Y_train)
print('Logistic Regression Training Accuracy:', train_acc)
test_acc, Y_pred = log_reg(X_test, Y_test)
print('\n\nLogistic Regression Test Accuracy:', test_acc)

#confusion matrix
conf_matrix = confusion_matrix(Y_test, Y_pred)
print('\n\nConfusion Matrix for Logistic Regression:\n\n', conf_matrix)

#Classification Report
class_rep = classification_report(Y_test, Y_pred)
print('\n\nClassification report for Logistic Regression:\n\n', class_rep)

accuracy_log = metrics.accuracy_score(Y_test, Y_pred)
print('\n\nAccuracy:', accuracy_log)

f1_log = f1_score(Y_test, Y_pred)
print('\n\nF1 score of Logistic Regression Model:', f1_log)
accuracy = []
f1 = []
accuracy.append(accuracy_log)
f1.append(f1_log)

fpr,tpr, label = roc_curve(Y_test, Y_pred)
plot_roc()
print('AUC:', auc(fpr,tpr))

precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred)
plot_precision_recall()
print('Average Precision score:', average_precision_score(Y_test, Y_pred))

"""Classifiers efficiency given area under the curve‚Åâ

0.90-1 = excellent (A)
0.80-0.90 = good (B)
0.70-0.80 = fair (C)
0.60-0.70 = poor (D)
0.50-0.60 = fail (F)

Decision Tree Classifier
"""

def dec_tree(X_train, Y_train):
  d_tree = DecisionTreeClassifier(max_depth=3)
  d_tree.fit(X_train, Y_train)

  score = d_tree.score(X_train, Y_train)
  Y_pred = d_tree.predict(X_test)

  return score, Y_pred

train_acc, Y_pred = dec_tree(X_train, Y_train)
print('Decision Tree Training Accuracy:', train_acc)
test_acc, Y_pred = dec_tree(X_test, Y_test)
print('\n\nDecision Tree Test Accuracy:', test_acc)

#confusion matrix
conf_matrix = confusion_matrix(Y_test, Y_pred)
print('\n\nConfusion Matrix for Decision Tree:\n\n', conf_matrix)

#Classification Report
class_rep = classification_report(Y_test, Y_pred)
print('\n\nClassification report for Decision Tree:\n\n', class_rep)

accuracy_tree = metrics.accuracy_score(Y_test, Y_pred)
print('\n\nAccuracy:', accuracy_tree)

f1_tree = f1_score(Y_test, Y_pred)
print('\n\nF1 score of Logistic Regression Model:', f1_tree)

accuracy.append(accuracy_tree)
f1.append(f1_tree)

fpr,tpr, label = roc_curve(Y_test, Y_pred)
plot_roc()
print('AUC:', auc(fpr,tpr))

precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred)
plot_precision_recall()
print('Average Precision score:', average_precision_score(Y_test, Y_pred))

"""Random Forest Classifier"""

def ran_forest(X_train, Y_train):
  r_for = RandomForestClassifier()
  r_for.fit(X_train, Y_train)

  score = r_for.score(X_train, Y_train)
  Y_pred = r_for.predict(X_test)

  return score, Y_pred

train_acc, Y_pred = ran_forest(X_train, Y_train)
print('Random Forest Training Accuracy:', train_acc)
test_acc, Y_pred = ran_forest(X_test, Y_test)
print('\n\nRandom Forest Test Accuracy:', test_acc)

#confusion matrix
conf_matrix = confusion_matrix(Y_test, Y_pred)
print('\n\nConfusion Matrix for Random Forest:\n\n', conf_matrix)

#Classification Report
class_rep = classification_report(Y_test, Y_pred)
print('\n\nClassification report for Random Forest:\n\n', class_rep)

accuracy_forest = metrics.accuracy_score(Y_test, Y_pred)
print('\n\nAccuracy:', accuracy_forest)

f1_forest = f1_score(Y_test, Y_pred)
print('\n\nF1 score of Logistic Regression Model:', f1_forest)

accuracy.append(accuracy_forest)
f1.append(f1_forest)

fpr,tpr, label = roc_curve(Y_test, Y_pred)
plot_roc()
print('AUC:', auc(fpr,tpr))

precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred)
plot_precision_recall()
print('Average Precision score:', average_precision_score(Y_test, Y_pred))

"""K Nearest Neighbors Classifier(KNN)"""

def k_neighbors(X_train, Y_train):
  k_nn = KNeighborsClassifier(n_neighbors=10)
  k_nn.fit(X_train, Y_train)

  score = k_nn.score(X_train, Y_train)
  Y_pred = k_nn.predict(X_test)

  return score, Y_pred

train_acc, Y_pred = k_neighbors(X_train, Y_train)
print('KNN Training Accuracy:', train_acc)
test_acc, Y_pred = k_neighbors(X_test, Y_test)
print('\n\nKNN Test Accuracy:', test_acc)

#confusion matrix
conf_matrix = confusion_matrix(Y_test, Y_pred)
print('\n\nConfusion Matrix for KNN classifier:\n\n', conf_matrix)

#Classification Report
class_rep = classification_report(Y_test, Y_pred)
print('\n\nClassification report for KNN classifier:\n\n', class_rep)

accuracy_KNN = metrics.accuracy_score(Y_test, Y_pred)
print('\n\nAccuracy:', accuracy_KNN)

f1_KNN = f1_score(Y_test, Y_pred)
print('\n\nF1 score of Logistic Regression Model:', f1_KNN)

accuracy.append(accuracy_KNN)
f1.append(f1_KNN)

fpr,tpr, label = roc_curve(Y_test, Y_pred)
plot_roc()
print('AUC:', auc(fpr,tpr))

precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred)
plot_precision_recall()
print('Average Precision score:', average_precision_score(Y_test, Y_pred))

"""Support Vector Machine Classification"""

def sup_vector(X_train, Y_train):
  svv_class = SVC()
  svv_class.fit(X_train, Y_train)

  score = svv_class.score(X_train, Y_train)
  Y_pred = svv_class.predict(X_test)

  return score, Y_pred

train_acc, Y_pred = sup_vector(X_train, Y_train)
print('SVM classifier Training Accuracy:', train_acc)
test_acc, Y_pred = sup_vector(X_test, Y_test)
print('\n\nSVM classifier Test Accuracy:', test_acc)

#confusion matrix
conf_matrix = confusion_matrix(Y_test, Y_pred)
print('\n\nConfusion Matrix for SVM classifier:\n\n', conf_matrix)

#Classification Report
class_rep = classification_report(Y_test, Y_pred)
print('\n\nClassification report for SVM classifier:\n\n', class_rep)

accuracy_SVM = metrics.accuracy_score(Y_test, Y_pred)
print('\n\nAccuracy:', accuracy_SVM)

f1_SVM = f1_score(Y_test, Y_pred)
print('\n\nF1 score of Logistic Regression Model:', f1_SVM)

accuracy.append(accuracy_SVM)
f1.append(f1_SVM)

fpr,tpr, label = roc_curve(Y_test, Y_pred)
plot_roc()
print('AUC:', auc(fpr,tpr))

precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred)
plot_precision_recall()
print('Average Precision score:', average_precision_score(Y_test, Y_pred))

"""Naive Bayes"""

def nav_bayes(X_train, Y_train):
  n_bayes = GaussianNB()
  n_bayes.fit(X_train, Y_train)

  score = n_bayes.score(X_train, Y_train)
  Y_pred = n_bayes.predict(X_test)

  return score, Y_pred

train_acc, Y_pred = nav_bayes(X_train, Y_train)
print('Naive Bayes classifier Training Accuracy:', train_acc)
test_acc, Y_pred = nav_bayes(X_test, Y_test)
print('\n\nNaive Bayes classifier Test Accuracy:', test_acc)

#confusion matrix
conf_matrix = confusion_matrix(Y_test, Y_pred)
print('\n\nConfusion Matrix for Naive Bayes classifier:\n\n', conf_matrix)

#Classification Report
class_rep = classification_report(Y_test, Y_pred)
print('\n\nClassification report for Naive Bayes classifier:\n\n', class_rep)

accuracy_Bayes = metrics.accuracy_score(Y_test, Y_pred)
print('\n\nAccuracy:', accuracy_Bayes)

f1_bayes = f1_score(Y_test, Y_pred)
print('\n\nF1 score of Logistic Regression Model:', f1_bayes)

accuracy.append(accuracy_Bayes)
f1.append(f1_bayes)

fpr,tpr, label = roc_curve(Y_test, Y_pred)
plot_roc()
print('AUC:', auc(fpr,tpr))

precision, recall, thresholds = precision_recall_curve(Y_test, Y_pred)
plot_precision_recall()
print('Average Precision score:', average_precision_score(Y_test, Y_pred))

"""RESULTS"""

print('Accuracy of Logistic Regression Model:',accuracy_log)
print('F1-score of Logistic Regression Model:',f1_log)
print('\nAccuracy of Decision Tree Classifier Model:',accuracy_tree)
print('F1-score of Decision Tree Classifier Model:',f1_tree)
print('\nAccuracy of Random Forest Classifier Model:',accuracy_forest)
print('F1-score of Random Forest Classifier Model:',f1_forest)
print('\nAccuracy of KNN Model:',accuracy_KNN)
print('F1-score of KNN Model:',f1_KNN)
print('\nAccuracy of SVM Model:',accuracy_SVM)
print('F1-score of SVM Model:',f1_SVM)
print('\nAccuracy of Naive Bayes Classifier Model:',accuracy_Bayes)
print('F1-score of Naive Bayes Classifier Model:',f1_bayes)

"""Visualizations"""

models = ['Logistic_Regression','Decision_Tree','Random_Forest','KNN','SVM','Naive_Bayes']
d = {'models': models,'accuracy': accuracy, 'f1': f1}
dplot = pd.DataFrame(data=d)
dplot

#sns.barplot(x='models', y='scores',hue='models', data=dplot)
dp = dplot.plot(kind='bar', figsize = (15,8), ylim = (0.9, 1), xlabel= ['Logistic_Regression','Decision_Tree','Random_Forest','KNN','SVM','Naive_Bayes'],
        color = ['gold', 'lightgreen'],
        rot = 0, title ='Various Models performance',
        edgecolor = 'grey', alpha = 0.5)


for p in dp.patches:
    dp.annotate(str(p.get_height()), (p.get_x() * 1.01, p.get_height() * 1.0005))
plt.show()